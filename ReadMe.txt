LinkedIn RAG Pipeline
## This project extracts, processes, and analyzes LinkedIn job postings while integrating Retrieval-Augmented Generation (RAG) for contextual responses using OpenAI.Features-Extract LinkedIn job postings via Selenium (prioritizing job posts over general feeds)-Clean & Filter text data to remove unwanted characters, numbers, and irrelevant content-Chunk text data for better processing-Generate embeddings using SentenceTransformer-Store embeddings in ChromaDB for RAG-Categorize posts based on job-related keywords-Analyze sentiment using TextBlob-Retrieve relevant context for user queries-Generate responses using OpenAI API-Store results in MongoDB and CSV-ZenML Orchestration to make the pipeline schedulable & manually triggerable## Setup1. Clone the repository:    ```bash    git clone https://github.com/yourusername/linkedin-job-rag-system.git    cd linkedin-job-rag-system    ```2. Set up the virtual environment:    ```bash    python3 -m venv venv    source venv/bin/activate  # on Windows use `venv\Scripts_ctivate`    ```3. Install the required dependencies:    ```bash    pip install -r requirements.txt    ```4. Configure your environment:    - Set your MongoDB URI and OpenAI API key in the `.env` file (not included in the repository for security reasons).    - Make sure to log in to LinkedIn via the Selenium browser window.5. Run the pipeline:    ```bash    python linkedin_rag_pipeline.py    ```## UsageAfter running the pipeline, you can interact with the system via the terminal to ask different job-related queries.## Notes-Ensure you have Google Chrome installed.-Selenium requires manual login (modify as needed).-MongoDB should be running for storing results.-The pipeline is schedulable and manually triggerable with ZenML.## GitHub Repository Files-linkedin_rag_pipeline.py: Main pipeline script.-requirements.txt: Dependencies list.-README.txt: Project documentation.